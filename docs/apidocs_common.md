## Layers

::: pytorch_tabular.models.common.layers.AddNorm
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.Embedding1dLayer
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.Embedding2dLayer
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.Lambda
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.ModuleWithInit
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.MultiHeadedAttention
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.PositionWiseFeedForward
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.PreEncoded1dLayer
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.Residual
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.SharedEmbeddings
    options:
            heading_level: 3
::: pytorch_tabular.models.common.layers.TransformerEncoderBlock
    options:
            heading_level: 3

## Activations

::: pytorch_tabular.models.common.activations.Entmax15Function
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.Entmoid15
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.GEGLU
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.PositionWiseFeedForward
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.ReGLU
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.SparsemaxFunction
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.SwiGLU
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.entmax15
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.entmoid15
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.sparsemax
    options:
            heading_level: 3
::: pytorch_tabular.models.common.activations.sparsemoid
    options:
            heading_level: 3
