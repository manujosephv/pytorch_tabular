{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "if not IN_COLAB:\n",
    "    os.chdir(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def make_mixed_regression(n_samples, n_features, n_categories):\n",
    "    X,y = make_regression(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5, n_targets=1)\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
    "    for col in cat_cols:\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\n",
    "    col_names = [] \n",
    "    num_col_names=[]\n",
    "    cat_col_names=[]\n",
    "    for i in range(X.shape[-1]):\n",
    "        if i in cat_cols:\n",
    "            col_names.append(f\"cat_col_{i}\")\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\n",
    "        if i in num_cols:\n",
    "            col_names.append(f\"num_col_{i}\")\n",
    "            num_col_names.append(f\"num_col_{i}\")\n",
    "    X = pd.DataFrame(X, columns=col_names)\n",
    "    y = pd.DataFrame(y, columns=[\"target\"])\n",
    "    data = X.join(y)\n",
    "    return data, cat_col_names, num_col_names\n",
    "\n",
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = mean_squared_error(y_true, y_pred)\n",
    "    val_f1 = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{tag} MSE: {val_acc} | {tag} MAE: {val_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Generate Synthetic Data \n",
    "\n",
    "First of all, let's create a synthetic data which is a mix of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data, cat_col_names, num_col_names = make_mixed_regression(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig, ModelConfig\n",
    "from pytorch_tabular.models import BaseModel\n",
    "from pytorch_tabular.models.common.layers import Embedding1dLayer\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Defining a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "PyTorch Tabular is very easy to extend and infinitely customizable. All the models that have been implemented in PyTorch Tabular inherits an Abstract Class `BaseModel` which is in fact a PyTorchLightning Model.\n",
    "\n",
    "It handles all the major functions like decoding the config params and setting up the loss and metrics. It also calculates the Loss and metrics and feeds it back to the PyTorch Lightning Trainer which does the back-propagation.\n",
    "\n",
    "If we look at the anatomy of a PyTorch Tabular model, there are three main components:\n",
    "\n",
    "1. **Embedding Layer** \n",
    "2. **Backbone**\n",
    "3. **Head**\n",
    "\n",
    "**Embedding Layer** takes the input from the dataloader, which is a dictionary with `categorical` and `continuous` tensors under those keys. The Embedding Layer converts this dictionary to a single tensor, handling the categorical tensors the right way. There are two Embedding Layers already implemented, EmbeddingLayer1d, EmbeddingLayer2d.\n",
    "\n",
    "**Backbone** is the main model architecture.\n",
    "\n",
    "**Head** is the linear layers which takes the output of the backbone and converts it into the output we desire.\n",
    "\n",
    "To encapsulate and enforce this structure, `BaseModel` requires us to define three `property` methods:\n",
    "1. `def embedding_layer(self)`\n",
    "2. `def backbone(self)`\n",
    "3. `def head(self)`\n",
    "\n",
    "There is another method `def _build_network(self)` which also needs to be defined mandatorily. We can use this method to define the embedding, backbone, head, and whatever other layers or components we need to use in the model.\n",
    "\n",
    "For standard Feed Forward layers as the head, we can also use a handly method in `BaseModel` called `_get_head_from_config` which will use the `head` and `head_config` you have set in the `ModelConfig` to initialize the right head automatically for you.\n",
    "\n",
    "An example of using it:\n",
    "```python\n",
    "self._head = self._get_head_from_config()\n",
    "```\n",
    "\n",
    "For standard flows, the `forward` method that is already defined would be enough.\n",
    "```python\n",
    "def forward(self, x: Dict):\n",
    "    x = self.embed_input(x) # Embeds the input dictionary and returns a tensor\n",
    "    x = self.compute_backbone(x) # Takes the tensor input and does representation learning\n",
    "    return self.compute_head(x) # transforms the backbone output to desired output, applies target range if necessary, and packs the output in the desired format.\n",
    "```\n",
    "What this allows us to do is to define any standard PyTorch model and use it as the **backbone**, and then use the rest of the PyTorch Tabular machinery to train, evaluate and log the model.\n",
    "\n",
    "While this is the bare minimum, you can redefine or use any of the Pytorch Lightning standard methods to tweak your model and training to your liking. The real beauty of this setup is that how much customization you need to do is really upto you. For standard workflows, you can change the minimum. And for highly unsual models, you can re-define any of the method in `BaseModel` (as long as the interfaces remain unchanged).\n",
    "\n",
    "\n",
    "In addition to the model, you will also need to define a config. Configs are python dataclasses and should inherit `ModelConfig` and will have all the parameters of the ModelConfig. by default. Any additional parameter should be defined in the dataclass. \n",
    "\n",
    "\n",
    "**Key things to note:**\n",
    "\n",
    "1. All the different parameters in the different configs(like TrainerConfig, OptimizerConfig, etc) are all available in `config` before calling `super()` and in `self.hparams` after.\n",
    "2. the input batch at the `forward` method is a dictionary with keys `continuous` and `categorical`\n",
    "3. In the `\\_build_network` method, save every component that you want access in the `forward` to `self`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Define a Config class to hold the hyperparameters of the model\n",
    "# We need to inherit ModelConfig so that default parameters like learning rate, head, head_config, etc. \n",
    "# are present in the config\n",
    "@dataclass\n",
    "class MyAwesomeModelConfig(ModelConfig):\n",
    "    use_batch_norm: bool = True\n",
    "        \n",
    "# Define the core model as a pure PyTorch model\n",
    "# The forward method takes in a tensor and outputs a tensor\n",
    "\n",
    "class MyAwesomeRegressionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hparams: DictConfig,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams # Save the config to be accessed in the model elsewhere\n",
    "        self._build_network()\n",
    "    \n",
    "    def _build_network(self):\n",
    "        #Continuous and Categorical Dimensions are precalculated and stored in the config\n",
    "        inp_dim = self.hparams.embedding_cat_dim + self.hparams.continuous_dim\n",
    "        self.linear_layer_1 = nn.Linear(inp_dim, 200)\n",
    "        self.linear_layer_2 = nn.Linear(inp_dim+200, 70)\n",
    "        self.linear_layer_3 = nn.Linear(inp_dim+70, 70)\n",
    "        self.input_batch_norm = nn.BatchNorm1d(self.hparams.continuous_dim)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            self.batch_norm_2 = nn.BatchNorm1d(inp_dim+200)\n",
    "            self.batch_norm_3 = nn.BatchNorm1d(inp_dim+70)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.output_dim = 70\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        inp = x\n",
    "        x = F.relu(self.linear_layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x,inp], 1)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            x = self.batch_norm_1(x)\n",
    "        x = F.relu(self.linear_layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x,inp], 1)\n",
    "        if self.hparams.use_batch_norm:\n",
    "            x = self.batch_norm_3(x)\n",
    "        x = self.linear_layer_3(x)\n",
    "        return x\n",
    "    \n",
    "    # It is also good practice to bundle the embedding scheme along with the core model\n",
    "    # This is so that the model encapsulates it's requirement of how to embed the input\n",
    "    # dictionary of categorical and continuous tensors and how to combine them into a single tensor.\n",
    "    # We can either use one of the predefined embedding layers in PyTorch Tabular\n",
    "    # Or define a custom embedding layer as well. Check Embedding1dLayer implementation \n",
    "    # on how to implement an embedding layer\n",
    "    def _build_embedding_layer(self):\n",
    "        return Embedding1dLayer(\n",
    "            continuous_dim=self.hparams.continuous_dim,\n",
    "            categorical_embedding_dims=self.hparams.embedding_dims,\n",
    "            embedding_dropout=self.hparams.embedding_dropout,\n",
    "            batch_norm_continuous_input=self.hparams.batch_norm_continuous_input,\n",
    "        )\n",
    "\n",
    "# Define the PyTorch Tabular model by inheriting BaseModel\n",
    "\n",
    "class MyAwesomeRegressionPTModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: DictConfig,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Save any attribute that you need in _build_network before calling super()\n",
    "        # After the super() call, the config will be saved as `hparams`\n",
    "        super().__init__(config, **kwargs)\n",
    "\n",
    "    def _build_network(self):\n",
    "        # Backbone - Initialize the PyTorch model we defined earlier\n",
    "        self._backbone = MyAwesomeRegressionModel(self.hparams)\n",
    "        # Initializing Embedding Layer using the method we defined in the backbone\n",
    "        self._embedding_layer = self._backbone._build_embedding_layer()\n",
    "        # Head - we can use the helper method to initialize standard linear head\n",
    "        self.head = self._get_head_from_config()\n",
    "    \n",
    "    # Now define the property methods which the BaseModel requires you to override\n",
    "    @property\n",
    "    def backbone(self):\n",
    "        return self._backbone\n",
    "\n",
    "    @property\n",
    "    def embedding_layer(self):\n",
    "        return self._embedding_layer\n",
    "\n",
    "    @property\n",
    "    def head(self):\n",
    "        return self._head\n",
    "    \n",
    "    # For more customizations, we can override forward, compute_backbone, compute_head etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define the Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "There is one deviation from the normal when we create a TabularModel object with the configs. Earlier the model was inferred from the config and initialized autmatically. But here, we have to use the `model_callable` parameter of the TabularModel and pass in the model class(not the initialized object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    "    devices=-1 # -1 means use all available\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"32\", # Number of nodes in each layer\n",
    "    activation=\"ReLU\", # Activation between each layers\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = MyAwesomeModelConfig(\n",
    "    task=\"regression\",\n",
    "    use_batch_norm =False,\n",
    "#     head = \"LinearHead\", #Linear Head\n",
    "#     head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    model_callable = MyAwesomeRegressionPTModel # When using custom model, we need to use the model_callable parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ConfigAttributeError",
     "evalue": "Missing key embedding_cat_dim\n    full_key: embedding_cat_dim\n    object_type=dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m tabular_model\u001b[38;5;241m.\u001b[39mprepare_dataloader(\n\u001b[1;32m      2\u001b[0m                 train\u001b[38;5;241m=\u001b[39mtrain, validation\u001b[38;5;241m=\u001b[39mval, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      3\u001b[0m             )\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtabular_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch_tabular/pytorch_tabular/pytorch_tabular/tabular_model.py:541\u001b[0m, in \u001b[0;36mTabularModel.prepare_model\u001b[0;34m(self, datamodule, loss, metrics, optimizer, optimizer_params)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferred_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_parse_config(\n\u001b[1;32m    535\u001b[0m     datamodule\u001b[38;5;241m.\u001b[39mupdate_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig), InferredConfig\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# if hasattr(self, \"model\") and self.model is not None and not reset:\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m#     logger.debug(\"Using the trained model...\")\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# logger.debug(\"Re-initializing the model. Trained weights are ignored.\")\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43minferred_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minferred_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Data Aware Initialization(for the models that need it)\u001b[39;00m\n\u001b[1;32m    550\u001b[0m model\u001b[38;5;241m.\u001b[39mdata_aware_initialization(datamodule)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionPTModel.__init__\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     68\u001b[0m     config: DictConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Save any attribute that you need in _build_network before calling super()\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# After the super() call, the config will be saved as `hparams`\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch_tabular/pytorch_tabular/pytorch_tabular/models/base_model.py:84\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, config, custom_loss, custom_metrics, custom_optimizer, custom_optimizer_params, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_hyperparameters(config)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# The concatenated output dim of the embedding layer\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_loss()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_metrics()\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionPTModel._build_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_network\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Backbone - Initialize the PyTorch model we defined earlier\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backbone \u001b[38;5;241m=\u001b[39m \u001b[43mMyAwesomeRegressionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Initializing Embedding Layer using the method we defined in the backbone\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backbone\u001b[38;5;241m.\u001b[39m_build_embedding_layer()\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionModel.__init__\u001b[0;34m(self, hparams, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams \u001b[38;5;241m=\u001b[39m hparams \u001b[38;5;66;03m# Save the config to be accessed in the model elsewhere\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionModel._build_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_network\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#Continuous and Categorical Dimensions are precalculated and stored in the config\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     inp_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_cat_dim\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mcontinuous_dim\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layer_1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(inp_dim, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layer_2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(inp_dim\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m70\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:357\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_impl(\n\u001b[1;32m    354\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, default_value\u001b[38;5;241m=\u001b[39m_DEFAULT_MARKER_, validate_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigAttributeError\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/base.py:211\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/_utils.py:844\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    841\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type \u001b[38;5;241m=\u001b[39m ref_type\n\u001b[1;32m    842\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type_str \u001b[38;5;241m=\u001b[39m ref_type_str\n\u001b[0;32m--> 844\u001b[0m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/_utils.py:742\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:353\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    358\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    359\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:444\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_impl\u001b[39m(\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    442\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:482\u001b[0m, in \u001b[0;36mDictConfig._get_node\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m throw_on_missing_key:\n\u001b[0;32m--> 482\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigKeyError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m throw_on_missing_value \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_is_missing():\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingMandatoryValue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing mandatory value: $KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConfigAttributeError\u001b[0m: Missing key embedding_cat_dim\n    full_key: embedding_cat_dim\n    object_type=dict"
     ]
    }
   ],
   "source": [
    "datamodule = tabular_model.prepare_dataloader(\n",
    "                train=train, validation=val, seed=42\n",
    "            )\n",
    "model = tabular_model.prepare_model(\n",
    "            datamodule\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training the Model \n",
    "\n",
    "The rest of the process is business-as-usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "ConfigAttributeError",
     "evalue": "Missing key batch_norm_continuous_input\n    full_key: batch_norm_continuous_input\n    object_type=dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtabular_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch_tabular/pytorch_tabular/pytorch_tabular/tabular_model.py:674\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, test, loss, metrics, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    672\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProviding test data in `fit` is deprecated and will be removed in next major release. Plese use `evaluate` for evaluating on test data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    673\u001b[0m         )\n\u001b[0;32m--> 674\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(model, datamodule, callbacks, max_epochs, min_epochs)\n",
      "File \u001b[0;32m~/pytorch_tabular/pytorch_tabular/pytorch_tabular/tabular_model.py:541\u001b[0m, in \u001b[0;36mTabularModel.prepare_model\u001b[0;34m(self, datamodule, loss, metrics, optimizer, optimizer_params)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferred_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_parse_config(\n\u001b[1;32m    535\u001b[0m     datamodule\u001b[38;5;241m.\u001b[39mupdate_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig), InferredConfig\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# if hasattr(self, \"model\") and self.model is not None and not reset:\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m#     logger.debug(\"Using the trained model...\")\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# logger.debug(\"Re-initializing the model. Trained weights are ignored.\")\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43minferred_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minferred_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Data Aware Initialization(for the models that need it)\u001b[39;00m\n\u001b[1;32m    550\u001b[0m model\u001b[38;5;241m.\u001b[39mdata_aware_initialization(datamodule)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionPTModel.__init__\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     config: DictConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Save any attribute that you need in _build_network before calling super()\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# After the super() call, the config will be saved as `hparams`\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch_tabular/pytorch_tabular/pytorch_tabular/models/base_model.py:84\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, config, custom_loss, custom_metrics, custom_optimizer, custom_optimizer_params, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_hyperparameters(config)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# The concatenated output dim of the embedding layer\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_loss()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_metrics()\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionPTModel._build_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backbone \u001b[38;5;241m=\u001b[39m MyAwesomeRegressionModel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Initializing Embedding Layer using the method we defined in the backbone\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_embedding_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Head - we can use the helper method to initialize standard linear head\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_head_from_config()\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mMyAwesomeRegressionModel._build_embedding_layer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_embedding_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Embedding1dLayer(\n\u001b[1;32m     55\u001b[0m         continuous_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mcontinuous_dim,\n\u001b[1;32m     56\u001b[0m         categorical_embedding_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39membedding_dims,\n\u001b[1;32m     57\u001b[0m         embedding_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39membedding_dropout,\n\u001b[0;32m---> 58\u001b[0m         batch_norm_continuous_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm_continuous_input\u001b[49m,\n\u001b[1;32m     59\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:357\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_impl(\n\u001b[1;32m    354\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, default_value\u001b[38;5;241m=\u001b[39m_DEFAULT_MARKER_, validate_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigAttributeError\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/base.py:211\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/_utils.py:844\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    841\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type \u001b[38;5;241m=\u001b[39m ref_type\n\u001b[1;32m    842\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type_str \u001b[38;5;241m=\u001b[39m ref_type_str\n\u001b[0;32m--> 844\u001b[0m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/_utils.py:742\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:353\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    358\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    359\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:444\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_impl\u001b[39m(\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    442\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch_env/lib/python3.8/site-packages/omegaconf-2.2.0-py3.8.egg/omegaconf/dictconfig.py:482\u001b[0m, in \u001b[0;36mDictConfig._get_node\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m throw_on_missing_key:\n\u001b[0;32m--> 482\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigKeyError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m throw_on_missing_value \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_is_missing():\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingMandatoryValue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing mandatory value: $KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConfigAttributeError\u001b[0m: Missing key batch_norm_continuous_input\n    full_key: batch_norm_continuous_input\n    object_type=dict"
     ]
    }
   ],
   "source": [
    "tabular_model.fit(train=train, validation=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40224f0d08024eeb9e75e081a9fe301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_mean_squared_error': tensor(14005.2725, device='cuda:0'),\n",
      " 'train_loss': tensor(3013.1719, device='cuda:0'),\n",
      " 'train_mean_squared_error': tensor(15613.8184, device='cuda:0'),\n",
      " 'valid_loss': tensor(1060.1337, device='cuda:0'),\n",
      " 'valid_mean_squared_error': tensor(15130.5811, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = tabular_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col_0</th>\n",
       "      <th>cat_col_1</th>\n",
       "      <th>num_col_2</th>\n",
       "      <th>num_col_3</th>\n",
       "      <th>num_col_4</th>\n",
       "      <th>num_col_5</th>\n",
       "      <th>num_col_6</th>\n",
       "      <th>num_col_7</th>\n",
       "      <th>num_col_8</th>\n",
       "      <th>num_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_col_12</th>\n",
       "      <th>num_col_13</th>\n",
       "      <th>cat_col_14</th>\n",
       "      <th>num_col_15</th>\n",
       "      <th>num_col_16</th>\n",
       "      <th>cat_col_17</th>\n",
       "      <th>num_col_18</th>\n",
       "      <th>num_col_19</th>\n",
       "      <th>target</th>\n",
       "      <th>target_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>0.321476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.836426</td>\n",
       "      <td>-0.200794</td>\n",
       "      <td>-1.372801</td>\n",
       "      <td>0.148776</td>\n",
       "      <td>1.607678</td>\n",
       "      <td>-0.710938</td>\n",
       "      <td>0.099704</td>\n",
       "      <td>2.494107</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.410212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416442</td>\n",
       "      <td>-0.843505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.150040</td>\n",
       "      <td>-0.636704</td>\n",
       "      <td>-119.618988</td>\n",
       "      <td>-174.084061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>0.291679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.213108</td>\n",
       "      <td>1.888767</td>\n",
       "      <td>1.209858</td>\n",
       "      <td>-0.684209</td>\n",
       "      <td>0.065715</td>\n",
       "      <td>-1.661187</td>\n",
       "      <td>-2.164594</td>\n",
       "      <td>-1.212303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.778092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.007395</td>\n",
       "      <td>0.304803</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.638452</td>\n",
       "      <td>0.672491</td>\n",
       "      <td>-207.596232</td>\n",
       "      <td>-171.813644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>-1.547951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.517188</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>2.356890</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>-0.415643</td>\n",
       "      <td>0.787585</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.324598</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.993319</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.121574</td>\n",
       "      <td>-0.146075</td>\n",
       "      <td>272.098656</td>\n",
       "      <td>198.954025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>0.911628</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.089328</td>\n",
       "      <td>-0.304067</td>\n",
       "      <td>0.984190</td>\n",
       "      <td>-1.114405</td>\n",
       "      <td>0.594178</td>\n",
       "      <td>-0.785370</td>\n",
       "      <td>-0.994555</td>\n",
       "      <td>-0.379163</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.217751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001061</td>\n",
       "      <td>-0.725295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.511682</td>\n",
       "      <td>-0.721897</td>\n",
       "      <td>21.896867</td>\n",
       "      <td>106.040825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>0.087945</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.320962</td>\n",
       "      <td>-0.231244</td>\n",
       "      <td>0.423397</td>\n",
       "      <td>-0.512270</td>\n",
       "      <td>-0.314670</td>\n",
       "      <td>-0.440412</td>\n",
       "      <td>-0.386701</td>\n",
       "      <td>0.966912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.654840</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.296487</td>\n",
       "      <td>1.079245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.327339</td>\n",
       "      <td>-0.365532</td>\n",
       "      <td>46.346326</td>\n",
       "      <td>51.485107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_col_0  cat_col_1  num_col_2  num_col_3  num_col_4  num_col_5  \\\n",
       "6252   0.321476        0.0  -0.836426  -0.200794  -1.372801   0.148776   \n",
       "4684   0.291679        1.0  -0.213108   1.888767   1.209858  -0.684209   \n",
       "1731  -1.547951        1.0   1.517188  -0.638986   2.356890   0.826815   \n",
       "4742   0.911628        3.0   0.089328  -0.304067   0.984190  -1.114405   \n",
       "4521   0.087945        2.0  -0.320962  -0.231244   0.423397  -0.512270   \n",
       "\n",
       "      num_col_6  num_col_7  num_col_8  num_col_9  ...  cat_col_12  num_col_13  \\\n",
       "6252   1.607678  -0.710938   0.099704   2.494107  ...         2.0    2.410212   \n",
       "4684   0.065715  -1.661187  -2.164594  -1.212303  ...         1.0    1.778092   \n",
       "1731  -0.570187  -0.415643   0.787585   0.027579  ...         2.0   -0.324598   \n",
       "4742   0.594178  -0.785370  -0.994555  -0.379163  ...         2.0   -0.217751   \n",
       "4521  -0.314670  -0.440412  -0.386701   0.966912  ...         3.0    1.654840   \n",
       "\n",
       "      cat_col_14  num_col_15  num_col_16  cat_col_17  num_col_18  num_col_19  \\\n",
       "6252         0.0   -0.416442   -0.843505         2.0    0.150040   -0.636704   \n",
       "4684         0.0   -1.007395    0.304803         2.0   -0.638452    0.672491   \n",
       "1731         2.0    1.993319    0.028488         1.0    1.121574   -0.146075   \n",
       "4742         0.0   -1.001061   -0.725295         0.0   -0.511682   -0.721897   \n",
       "4521         3.0    1.296487    1.079245         3.0    0.327339   -0.365532   \n",
       "\n",
       "          target  target_prediction  \n",
       "6252 -119.618988        -174.084061  \n",
       "4684 -207.596232        -171.813644  \n",
       "1731  272.098656         198.954025  \n",
       "4742   21.896867         106.040825  \n",
       "4521   46.346326          51.485107  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout MSE: 2515.075280931874 | Holdout MAE: 38.42137329388225\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
