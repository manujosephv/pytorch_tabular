{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "try:\r\n",
    "  import google.colab\r\n",
    "  IN_COLAB = True\r\n",
    "except:\r\n",
    "  IN_COLAB = False\r\n",
    "if not IN_COLAB:\r\n",
    "    os.chdir(\"..\")\r\n",
    "from sklearn.datasets import fetch_covtype\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import lightgbm as lgb\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import accuracy_score, f1_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import category_encoders as ce\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_classification_data():\r\n",
    "    dataset = fetch_covtype(data_home=\"data\")\r\n",
    "    data = np.hstack([dataset.data, dataset.target.reshape(-1, 1)])\r\n",
    "    col_names = [f\"feature_{i}\" for i in range(data.shape[-1])]\r\n",
    "    col_names[-1] = \"target\"\r\n",
    "    data = pd.DataFrame(data, columns=col_names)\r\n",
    "    data[\"feature_0_cat\"] = pd.qcut(data[\"feature_0\"], q=4)\r\n",
    "    data[\"feature_0_cat\"] = \"feature_0_\" + data.feature_0_cat.cat.codes.astype(str)\r\n",
    "    test_idx = data.sample(int(0.2 * len(data)), random_state=42).index\r\n",
    "    test = data[data.index.isin(test_idx)]\r\n",
    "    train = data[~data.index.isin(test_idx)]\r\n",
    "    return (train, test, [\"target\"])\r\n",
    "\r\n",
    "def print_metrics(y_true, y_pred, tag):\r\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\r\n",
    "        y_true = y_true.values\r\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\r\n",
    "        y_pred = y_pred.values\r\n",
    "    if y_true.ndim>1:\r\n",
    "        y_true=y_true.ravel()\r\n",
    "    if y_pred.ndim>1:\r\n",
    "        y_pred=y_pred.ravel()\r\n",
    "    val_acc = accuracy_score(y_true, y_pred)\r\n",
    "    val_f1 = f1_score(y_true, y_pred, average=\"macro\")\r\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Forest Cover Data"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train, test, target_col = load_classification_data()\n",
    "train, val = train_test_split(train, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cat_col_names = [\"feature_0_cat\"]\n",
    "num_col_names = [col for col in train.columns if col not in cat_col_names+target_col]"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "encoder = ce.OneHotEncoder(cols=cat_col_names)\n",
    "train_transform = encoder.fit_transform(train)\n",
    "val_transform = encoder.transform(val)\n",
    "test_transform = encoder.transform(test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\miniconda3\\envs\\df_encoder\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline\n",
    "\n",
    "Let's use the default LightGBM model as a baseline."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "clf = lgb.LGBMClassifier(random_state=42, n_jobs=-1)\n",
    "clf.fit(train_transform.drop(columns=target_col), train_transform[target_col].values.ravel())\n",
    "val_pred = clf.predict(val_transform.drop(columns=target_col))\n",
    "print_metrics(val_transform[target_col], val_pred, \"Validation\")\n",
    "test_pred = clf.predict(test_transform.drop(columns='target'))\n",
    "print_metrics(test_transform[target_col], test_pred, \"Holdout\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Acc: 0.8528953641472251 | Validation F1: 0.825508819288814\n",
      "Holdout Acc: 0.8517409338909829 | Holdout F1: 0.8175438711213123\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CategoryEmbedding Model"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, NodeConfig, TabNetModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.categorical_encoders import CategoricalEmbeddingTransformer"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data_config = DataConfig(\n",
    "    target=target_col, #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    "    continuous_feature_transform=\"quantile_normal\",\n",
    "    normalize_continuous_features=True\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=1000,\n",
    "    gpus=-1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"4096-4096-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    learning_rate = 1e-3,\n",
    "    metrics=[\"accuracy\", \"f1\"],\n",
    "    metrics_params=[{},{\"average\":\"micro\"}]\n",
    ")\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model.fit(train=train, test=test)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "result = tabular_model.evaluate(test)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00378c57de1c4c0590167cd336e48594",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.7331, device='cuda:0'),\n",
      " 'train_accuracy': tensor(0.6792, device='cuda:0'),\n",
      " 'train_loss': tensor(0.7323, device='cuda:0'),\n",
      " 'valid_accuracy': tensor(0.7256, device='cuda:0'),\n",
      " 'valid_loss': tensor(0.6508, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[{'train_loss': 0.7322986721992493, 'valid_loss': 0.6507797837257385, 'valid_accuracy': 0.7255920171737671, 'train_accuracy': 0.6791602969169617, 'test_accuracy': 0.7330596446990967}]\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the prediction as a dataframe, we can use the `predict` method. This will add predictions to the same dataframe that was passed in. For classification problems, we get both the probabilities and the final prediction taking 0.5 as the threshold"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "pred_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0      2596.0       51.0        3.0      258.0        0.0      510.0   \n",
       "2      2804.0      139.0        9.0      268.0       65.0     3180.0   \n",
       "6      2606.0       45.0        7.0      270.0        5.0      633.0   \n",
       "7      2605.0       49.0        4.0      234.0        7.0      573.0   \n",
       "12     2742.0      134.0       22.0      150.0       69.0     3215.0   \n",
       "\n",
       "    feature_6  feature_7  feature_8  feature_9  ...  target  feature_0_cat  \\\n",
       "0       221.0      232.0      148.0     6279.0  ...     5.0              4   \n",
       "2       234.0      238.0      135.0     6121.0  ...     2.0              4   \n",
       "6       222.0      225.0      138.0     6256.0  ...     5.0              4   \n",
       "7       222.0      230.0      144.0     6228.0  ...     5.0              4   \n",
       "12      248.0      224.0       92.0     6091.0  ...     2.0              4   \n",
       "\n",
       "    1.0_probability  2.0_probability  3.0_probability  4.0_probability  \\\n",
       "0          0.091117         0.903000         0.000026     3.998069e-07   \n",
       "2          0.106677         0.869829         0.000271     2.589042e-06   \n",
       "6          0.109588         0.880163         0.000282     4.664133e-06   \n",
       "7          0.332467         0.664670         0.000001     3.689538e-08   \n",
       "12         0.043308         0.917662         0.000034     1.030319e-06   \n",
       "\n",
       "    5.0_probability  6.0_probability  7.0_probability  prediction  \n",
       "0          0.005816         0.000012         0.000030         2.0  \n",
       "2          0.022369         0.000835         0.000017         2.0  \n",
       "6          0.009279         0.000315         0.000369         2.0  \n",
       "7          0.002125         0.000001         0.000736         2.0  \n",
       "12         0.038968         0.000015         0.000012         2.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_0_cat</th>\n",
       "      <th>1.0_probability</th>\n",
       "      <th>2.0_probability</th>\n",
       "      <th>3.0_probability</th>\n",
       "      <th>4.0_probability</th>\n",
       "      <th>5.0_probability</th>\n",
       "      <th>6.0_probability</th>\n",
       "      <th>7.0_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.091117</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>3.998069e-07</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.106677</td>\n",
       "      <td>0.869829</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>2.589042e-06</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2606.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109588</td>\n",
       "      <td>0.880163</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>4.664133e-06</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2605.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.332467</td>\n",
       "      <td>0.664670</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.689538e-08</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2742.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.917662</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.030319e-06</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print_metrics(test['target'], pred_df[\"prediction\"], tag=\"Holdout\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Holdout Acc: 0.6147828780915991 | Holdout F1: 0.3269562480388109\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract the Learned Embedding\n",
    "\n",
    "For the models that support (CategoryEmbeddingModel and CategoryEmbeddingNODE), we can extract the learned embeddings into a sci-kit learn style Transformer. You can use this in your Sci-kit Learn pipelines and workflows as a drop in replacement."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "transformer = CategoricalEmbeddingTransformer(tabular_model)\n",
    "train_transform = transformer.fit_transform(train)\n",
    "clf = lgb.LGBMClassifier(random_state=42)\n",
    "clf.fit(train_transform.drop(columns='target'), train_transform['target'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "val_transform = transformer.transform(val)\n",
    "val_pred = clf.predict(val_transform.drop(columns=target_col))\n",
    "print_metrics(val_transform[target_col], val_pred, \"Validation\")\n",
    "test_transform = transformer.transform(test)\n",
    "test_pred = clf.predict(test_transform.drop(columns=target_col))\n",
    "print_metrics(test_transform[target_col], test_pred, \"Holdout\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Acc: 0.8561396865829626 | Validation F1: 0.8260076319996745\n",
      "Holdout Acc: 0.8555876835166348 | Holdout F1: 0.8233005227790506\n"
     ]
    }
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "|Split|One-Hot Encoding|Neural Embedding|\n",
    "|--|--|--|\n",
    "|Validation Accuracy|85.28%|**85.61%**|\n",
    "|Validation F1|82.55%|**82.60%**|\n",
    "|Holdout Accuracy|85.17%|**85.55%**|\n",
    "|Holdout F1|81.75%|**82.33%**|\n"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:df_encoder]",
   "language": "python",
   "name": "conda-env-df_encoder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}