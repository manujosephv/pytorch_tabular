{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import logging\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def make_mixed_classification(n_samples, n_features, n_categories):\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5)\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])), k=n_categories)\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
    "    for col in cat_cols:\n",
    "        X[:, col] = pd.qcut(X[:, col], q=4).codes.astype(int)\n",
    "    col_names = []\n",
    "    num_col_names = []\n",
    "    cat_col_names = []\n",
    "    for i in range(X.shape[-1]):\n",
    "        if i in cat_cols:\n",
    "            col_names.append(f\"cat_col_{i}\")\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\n",
    "        if i in num_cols:\n",
    "            col_names.append(f\"num_col_{i}\")\n",
    "            num_col_names.append(f\"num_col_{i}\")\n",
    "    X = pd.DataFrame(X, columns=col_names)\n",
    "    y = pd.Series(y, name=\"target\")\n",
    "    data = X.join(y)\n",
    "    return data, cat_col_names, num_col_names\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim > 1:\n",
    "        y_true = y_true.ravel()\n",
    "    if y_pred.ndim > 1:\n",
    "        y_pred = y_pred.ravel()\n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    val_f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Generate Synthetic Data \n",
    "\n",
    "First of all, let's create a synthetic data which is a mix of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data, cat_col_names, num_col_names = make_mixed_classification(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import (\n",
    "    CategoryEmbeddingModelConfig,\n",
    "    NodeConfig,\n",
    "    TabNetModelConfig,\n",
    "    GatedAdditiveTreeEnsembleConfig,\n",
    ")\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Test-Time Augumentation\n",
    "\n",
    "> Test time augmentation (TTA) is a popular technique in computer vision. TTA aims at boosting the model accuracy by using data augmentation on the inference stage. The idea behind TTA is simple: for each test image, we create multiple versions that are a little different from the original (e.g., cropped or flipped). Next, we predict labels for the test images and created copies and average model predictions over multiple versions of each image. This usually helps to improve the accuracy irrespective of the underlying model.\n",
    "- from [Test-Time Augmentation for Tabular Data](https://kozodoi.me/python/structured%20data/test-time%20augmentation/2021/09/08/tta-tabular.html)\n",
    "\n",
    "Using the Low-level API, we can also implement test-time augumentation for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"target\"\n",
    "    ],  # target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    early_stopping=\"valid_loss\",  # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode=\"min\",  # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5,  # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\",  # Save best checkpoint monitoring val_loss\n",
    "    load_best=True,  # After training, load the best checkpoint\n",
    "    #     progress_bar=\"none\", # Turning off Progress bar\n",
    "    #     trainer_kwargs=dict(\n",
    "    #         enable_model_summary=False # Turning off model summary\n",
    "    #     )\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", dropout=0.1, initialization=\"kaiming\"  # No additional layer in head, just a mapping layer to output_dim\n",
    ").__dict__  # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model1_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\",  # Activation between each layers\n",
    "    learning_rate=1e-3,\n",
    "    head=\"LinearHead\",  # Linear Head\n",
    "    head_config=head_config,  # Linear Head Config\n",
    ")\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\",  # Activation between each layers\n",
    "    learning_rate=1e-3,\n",
    "    head=\"LinearHead\",  # Linear Head\n",
    "    head_config=head_config,  # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/manujosephv/pytorch_tabular/.env/tabular_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /home/manujosephv/pytorch_tabular/docs/tutorials/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  817 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │     92 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │  1.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  817 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │     92 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │  1.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss          │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 818 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 818 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 3                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 818 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 818 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 3                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904ed8c25e7540faa7b1b6a7a5093033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\r\n",
       "\u001b[2K/home/manujosephv/pytorch_tabular/.env/tabular_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\r\n",
       "\u001b[2K/home/manujosephv/pytorch_tabular/.env/tabular_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\r\n",
       "\u001b[2K/home/manujosephv/pytorch_tabular/.env/tabular_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\r\n",
       "\u001b[2K/home/manujosephv/pytorch_tabular/.env/tabular_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x7f0c8a1f6080>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule = tabular_model.prepare_dataloader(train=train, validation=val, seed=42)\n",
    "model = tabular_model.prepare_model(datamodule)\n",
    "tabular_model.train(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1249a2622bc24b06a71bd08032b04cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking original predictions\n",
    "orig_pred_df = tabular_model.predict(test)\n",
    "pred_df = orig_pred_df[[\"0_probability\", \"1_probability\"]].copy()\n",
    "pred_df.columns = [\"0_probability_0\", \"1_probability_0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tta = 4  # number of augumentations\n",
    "noise_scale = 0.05  # Scale of the noise. Higher means larger perturbation of features\n",
    "categorical_swap_proba = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b0f583f4e340c0830cc6903243f1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14c0cc28354440287abc4ca35dc980f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de23eb5e6564d6d974000eebccfec3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122872f4ec994dbe83e90a381f232a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_tabular.ssl_models.common.noise_generators import SwapNoiseCorrupter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "for i in range(num_tta):\n",
    "    noised_test = test.copy()\n",
    "    corrupter = SwapNoiseCorrupter(\n",
    "        probas=[categorical_swap_proba for _ in range(len(datamodule.config.categorical_cols))]\n",
    "    )\n",
    "    for col in datamodule.config.continuous_cols:\n",
    "        # Adding gaussian noise to continuous columns\n",
    "        noised_test[col] = (\n",
    "            noised_test[col] + noise_scale * np.random.normal(0, 1, size=len(noised_test)) * noised_test[col].std()\n",
    "        )\n",
    "    # For categorical we can swap values\n",
    "    # for this we can reuse the SwapNoiseCorrupter in PyTorch Tabular\n",
    "    cat_cols = torch.from_numpy(noised_test[datamodule.config.categorical_cols].values)\n",
    "    cat_cols, _ = corrupter(cat_cols)\n",
    "    noised_test.loc[:, datamodule.config.categorical_cols] = cat_cols.numpy()\n",
    "\n",
    "    pred_df[[f\"0_probability_{i+1}\", f\"1_probability_{i+1}\"]] = 0\n",
    "    pred_df[[f\"0_probability_{i+1}\", f\"1_probability_{i+1}\"]] = tabular_model.predict(noised_test)[\n",
    "        [\"0_probability\", \"1_probability\"]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.924 | TTA Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "# Calculating mean probability across different augumentations\n",
    "pred_df[\"0_prob\"] = pred_df[[col for col in pred_df.columns if col.startswith(\"0_probability\")]].mean(axis=1)\n",
    "pred_df[\"1_prob\"] = pred_df[[col for col in pred_df.columns if col.startswith(\"1_probability\")]].mean(axis=1)\n",
    "# Calculating final preds from probabilisites using 0.5 threshold\n",
    "pred_df[\"original_pred\"] = pred_df[\"1_probability_0\"] > 0.5\n",
    "pred_df[\"tta_pred\"] = pred_df[\"1_prob\"] > 0.5\n",
    "# Calculating metrics\n",
    "orig_acc = accuracy_score(test[\"target\"].values, pred_df[\"original_pred\"].values)\n",
    "tta_acc = accuracy_score(test[\"target\"].values, pred_df[\"tta_pred\"].values)\n",
    "print(f\"Original Accuracy: {orig_acc} | TTA Accuracy: {tta_acc}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`noise_scale` and `categorical_swap_proba`  should be tuned to find the right amount of noise to be injected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad8d5d2789703c7b1c2f7bfaada1cbd3aa0ac53e2e4e1cae5da195f5520da229"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
