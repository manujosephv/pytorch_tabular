{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_tabular.utils import load_covertype_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data, cat_col_names, num_col_names, target_col = load_covertype_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel, model_sweep\n",
    "from pytorch_tabular.models import (\n",
    "    CategoryEmbeddingModelConfig,\n",
    "    DANetConfig,\n",
    "    GANDALFConfig,\n",
    "    FTTransformerConfig,\n",
    "    TabNetModelConfig\n",
    ")\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sweep\n",
    "\n",
    "Define the data config, trainer config, and optimizer config and do a sweep of multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        target_col\n",
    "    ],  # target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024,\n",
    "    max_epochs=25,\n",
    "    auto_lr_find=True,\n",
    "    early_stopping=\"valid_loss\",  # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode=\"min\",  # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5,  # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\",  # Save best checkpoint monitoring val_loss\n",
    "    load_best=True,  # After training, load the best checkpoint\n",
    "    progress_bar=\"none\",  # Turning off Progress bar\n",
    "    trainer_kwargs=dict(enable_model_summary=False),  # Turning off model summary\n",
    "    accelerator=\"cpu\",\n",
    "    fast_dev_run=False,\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", dropout=0.1, initialization=\"kaiming\"  # No additional layer in head, just a mapping layer to output_dim\n",
    ").__dict__  # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sweep API\n",
    "\n",
    "<!-- Args:\n",
    "    task (str): The type of prediction task. Either 'classification' or 'regression'\n",
    "\n",
    "    train (pd.DataFrame): The training data\n",
    "\n",
    "    test (pd.DataFrame): The test data on which performance is evaluated\n",
    "\n",
    "    data_config (Union[DataConfig, str]): DataConfig object or path to the yaml file.\n",
    "\n",
    "    optimizer_config (Union[OptimizerConfig, str]): OptimizerConfig object or path to the yaml file.\n",
    "\n",
    "    trainer_config (Union[TrainerConfig, str]): TrainerConfig object or path to the yaml file.\n",
    "\n",
    "    models (Union[str, List[Union[ModelConfig, str]]], optional): The list of models to compare. This can be one of\n",
    "            the presets defined in ``pytorch_tabular.MODEL_SWEEP_PRESETS`` or a list of ``ModelConfig`` objects.\n",
    "            Defaults to \"fast\".\n",
    "\n",
    "    metrics (Optional[List[str]]): the list of metrics you need to track during training. The metrics\n",
    "            should be one of the functional metrics implemented in ``torchmetrics``. By default, it is\n",
    "            accuracy if classification and mean_squared_error for regression\n",
    "\n",
    "    metrics_prob_input (Optional[bool]): Is a mandatory parameter for classification metrics defined in\n",
    "            the config. This defines whether the input to the metric function is the probability or the class.\n",
    "            Length should be same as the number of metrics. Defaults to None.\n",
    "\n",
    "    metrics_params (Optional[List]): The parameters to be passed to the metrics function. `task` is forced to\n",
    "            be `multiclass` because the multiclass version can handle binary as well and for simplicity we are\n",
    "            only using `multiclass`.\n",
    "\n",
    "    validation (Optional[DataFrame], optional):\n",
    "            If provided, will use this dataframe as the validation while training.\n",
    "            Used in Early Stopping and Logging. If left empty, will use 20% of Train data as validation.\n",
    "            Defaults to None.\n",
    "\n",
    "    experiment_config (Optional[Union[ExperimentConfig, str]], optional): ExperimentConfig object or path to the yaml file.\n",
    "\n",
    "    common_model_args (Optional[dict], optional): The model argument which are common to all models. The list of params can\n",
    "        be found in ``ModelConfig``. If not provided, will use defaults. Defaults to {}.\n",
    "\n",
    "    rank_metric (Optional[Tuple[str, str]], optional): The metric to use for ranking the models. The first element of the tuple\n",
    "        is the metric name and the second element is the direction. Defaults to ('loss', \"lower_is_better\").\n",
    "\n",
    "    return_best_model (bool, optional): If True, will return the best model. Defaults to True.\n",
    "\n",
    "    seed (int, optional): The seed for reproducibility. Defaults to 42.\n",
    "\n",
    "    ignore_oom (bool, optional): If True, will ignore the Out of Memory error and continue with the next model. -->\n",
    "\n",
    "The model sweep enables you to quickly sweep thorugh different models and configurations. It takes in a list of model configs or one of the presets defined in ``model_comparator.MODEL_PRESETS`` and trains them on the data. It then ranks the models based on the metric provided and returns the best model.\n",
    "\n",
    "These are the major args:\n",
    "- ``task``: The type of prediction task. Either 'classification' or 'regression'\n",
    "- ``train``: The training data\n",
    "- ``test``: The test data on which performance is evaluated\n",
    "- all the config objects can be passed as either the object or the path to the yaml file.\n",
    "- ``models``: The list of models to compare. This can be one of the presets defined in ``pytorch_tabular.MODEL_SWEEP_PRESETS`` or a list of ``ModelConfig`` objects.\n",
    "- ``metrics``: the list of metrics you need to track during training. The metrics should be one of the functional metrics implemented in ``torchmetrics``. By default, it is accuracy if classification and mean_squared_error for regression\n",
    "- ``metrics_prob_input``: Is a mandatory parameter for classification metrics defined in the config. This defines whether the input to the metric function is the probability or the class. Length should be same as the number of metrics. Defaults to None.\n",
    "- ``metrics_params``: The parameters to be passed to the metrics function. \n",
    "- ``rank_metric``: The metric to use for ranking the models. The first element of the tuple is the metric name and the second element is the direction. Defaults to ('loss', \"lower_is_better\").\n",
    "- ``return_best_model``: If True, will return the best model. Defaults to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lite', 'full', 'high_memory'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "MODEL_SWEEP_PRESETS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"256-128-64\",\n",
    "    head=\"LinearHead\",\n",
    "    head_config=head_config,\n",
    ")\n",
    "\n",
    "danet = DANetConfig(\n",
    "    task=\"classification\",\n",
    "    n_layers=8,\n",
    "    abstlay_dim_1=8,\n",
    "    k=5,\n",
    "    head=\"LinearHead\",\n",
    "    head_config=head_config,\n",
    ")\n",
    "\n",
    "gandalf = GANDALFConfig(\n",
    "    task=\"classification\",\n",
    "    gflu_stages=6,\n",
    "    head=\"LinearHead\",\n",
    "    head_config=head_config,\n",
    ")\n",
    "\n",
    "tabnet = TabNetModelConfig(\n",
    "    task=\"classification\",\n",
    "    n_d=32,\n",
    "    n_a=32,\n",
    "    n_steps=3,\n",
    "    gamma=1.5,\n",
    "    n_independent=1,\n",
    "    n_shared=2,\n",
    "    head=\"LinearHead\",\n",
    "    head_config=head_config,\n",
    ")\n",
    "model_list = [mlp, danet, gandalf, tabnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9c3b86cf9d4d1b8d6fa57809c4557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92eca0a84074c13ad5301db57b51ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636eff4dae534662b9d8cbbca3e2f554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ac6f5dbf1d47e6969aab77e4609e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0dd74db2ca467e937cf4755fb53281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_df, best_model = model_sweep(\n",
    "    task=\"classification\",  # One of \"classification\", \"regression\"\n",
    "    train=train,\n",
    "    test=test,\n",
    "    data_config=data_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    model_list=model_list,\n",
    "    common_model_args=dict(head=\"LinearHead\", head_config=head_config),\n",
    "    metrics=['accuracy', \"f1_score\"],\n",
    "    metrics_params=[{}, {\"average\": \"weighted\"}],\n",
    "    metrics_prob_input=[False, True],\n",
    "    rank_metric=(\"accuracy\", \"higher_is_better\"),\n",
    "    progress_bar=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7542c_row0_col2, #T_7542c_row0_col3, #T_7542c_row0_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7542c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7542c_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_7542c_level0_col1\" class=\"col_heading level0 col1\" ># Params</th>\n",
       "      <th id=\"T_7542c_level0_col2\" class=\"col_heading level0 col2\" >test_loss</th>\n",
       "      <th id=\"T_7542c_level0_col3\" class=\"col_heading level0 col3\" >test_accuracy</th>\n",
       "      <th id=\"T_7542c_level0_col4\" class=\"col_heading level0 col4\" >test_f1_score</th>\n",
       "      <th id=\"T_7542c_level0_col5\" class=\"col_heading level0 col5\" >time_taken_per_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7542c_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_7542c_row0_col0\" class=\"data row0 col0\" >GANDALFModel</td>\n",
       "      <td id=\"T_7542c_row0_col1\" class=\"data row0 col1\" >43 T</td>\n",
       "      <td id=\"T_7542c_row0_col2\" class=\"data row0 col2\" >0.194132</td>\n",
       "      <td id=\"T_7542c_row0_col3\" class=\"data row0 col3\" >0.923134</td>\n",
       "      <td id=\"T_7542c_row0_col4\" class=\"data row0 col4\" >0.922943</td>\n",
       "      <td id=\"T_7542c_row0_col5\" class=\"data row0 col5\" >9.188667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7542c_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_7542c_row1_col0\" class=\"data row1 col0\" >TabNetModel</td>\n",
       "      <td id=\"T_7542c_row1_col1\" class=\"data row1 col1\" >50 T</td>\n",
       "      <td id=\"T_7542c_row1_col2\" class=\"data row1 col2\" >0.269097</td>\n",
       "      <td id=\"T_7542c_row1_col3\" class=\"data row1 col3\" >0.891575</td>\n",
       "      <td id=\"T_7542c_row1_col4\" class=\"data row1 col4\" >0.891314</td>\n",
       "      <td id=\"T_7542c_row1_col5\" class=\"data row1 col5\" >14.920577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7542c_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "      <td id=\"T_7542c_row2_col0\" class=\"data row2 col0\" >CategoryEmbeddingModel</td>\n",
       "      <td id=\"T_7542c_row2_col1\" class=\"data row2 col1\" >51 T</td>\n",
       "      <td id=\"T_7542c_row2_col2\" class=\"data row2 col2\" >0.273254</td>\n",
       "      <td id=\"T_7542c_row2_col3\" class=\"data row2 col3\" >0.889448</td>\n",
       "      <td id=\"T_7542c_row2_col4\" class=\"data row2 col4\" >0.888622</td>\n",
       "      <td id=\"T_7542c_row2_col5\" class=\"data row2 col5\" >7.662767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7542c_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_7542c_row3_col0\" class=\"data row3 col0\" >DANetModel</td>\n",
       "      <td id=\"T_7542c_row3_col1\" class=\"data row3 col1\" >78 T</td>\n",
       "      <td id=\"T_7542c_row3_col2\" class=\"data row3 col2\" >0.328478</td>\n",
       "      <td id=\"T_7542c_row3_col3\" class=\"data row3 col3\" >0.865359</td>\n",
       "      <td id=\"T_7542c_row3_col4\" class=\"data row3 col4\" >0.862838</td>\n",
       "      <td id=\"T_7542c_row3_col5\" class=\"data row3 col5\" >55.021350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f34e8515d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_df.drop(columns=[\"params\", \"time_taken\", \"epochs\"]).style.highlight_max(\n",
    "    subset=[\"test_accuracy\", \"test_f1_score\"], color=\"lightgreen\"\n",
    ").highlight_min(subset=[\"test_loss\"], color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the `lite` preset which is a set of four models which have comparable # of params and trains relatively faster with less memory requirements.\n",
    "\n",
    "We can see that GANDALF performs the best in terms of accuracy, loss and f1 score. We can also see that the training time is comparable to regular MLP. A natural next step would be to tune the model a but more and find the best parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad8d5d2789703c7b1c2f7bfaada1cbd3aa0ac53e2e4e1cae5da195f5520da229"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
