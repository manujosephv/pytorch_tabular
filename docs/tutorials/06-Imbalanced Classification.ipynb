{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import make_classification\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, f1_score\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "try:\r\n",
    "  import google.colab\r\n",
    "  IN_COLAB = True\r\n",
    "except:\r\n",
    "  IN_COLAB = False\r\n",
    "if not IN_COLAB:\r\n",
    "    os.chdir(\"..\")\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def make_imbalanced_mixed_classification(n_samples, n_features, n_categories):\r\n",
    "    X,y = make_classification(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5, weights=[0.7], flip_y=0.3)\r\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\r\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\r\n",
    "    for col in cat_cols:\r\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\r\n",
    "    col_names = [] \r\n",
    "    num_col_names=[]\r\n",
    "    cat_col_names=[]\r\n",
    "    for i in range(X.shape[-1]):\r\n",
    "        if i in cat_cols:\r\n",
    "            col_names.append(f\"cat_col_{i}\")\r\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\r\n",
    "        if i in num_cols:\r\n",
    "            col_names.append(f\"num_col_{i}\")\r\n",
    "            num_col_names.append(f\"num_col_{i}\")\r\n",
    "    X = pd.DataFrame(X, columns=col_names)\r\n",
    "    y = pd.Series(y, name=\"target\")\r\n",
    "    data = X.join(y)\r\n",
    "    return data, cat_col_names, num_col_names\r\n",
    "\r\n",
    "def print_metrics(y_true, y_pred, tag):\r\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\r\n",
    "        y_true = y_true.values\r\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\r\n",
    "        y_pred = y_pred.values\r\n",
    "    if y_true.ndim>1:\r\n",
    "        y_true=y_true.ravel()\r\n",
    "    if y_pred.ndim>1:\r\n",
    "        y_pred=y_pred.ravel()\r\n",
    "    val_acc = accuracy_score(y_true, y_pred)\r\n",
    "    val_f1 = f1_score(y_true, y_pred)\r\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Synthetic Data \n",
    "\n",
    "First of all, let's create a synthetic data which is a mix of numerical and categorical features"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "data, cat_col_names, num_col_names = make_imbalanced_mixed_classification(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the Library"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Configs\n"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    gpus=-1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    learning_rate = 1e-3,\n",
    "    metrics=[\"f1\",\"accuracy\"], \n",
    "    metrics_params=[{\"num_classes\":2},{}]\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model "
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "tabular_model.fit(train=train, validation=val)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false",
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "result = tabular_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5a1f5598ef41d89c251246c955e502",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6652, device='cuda:0'),\n",
      " 'test_f1': tensor(0.6652, device='cuda:0'),\n",
      " 'train_accuracy': tensor(0.6135, device='cuda:0'),\n",
      " 'train_f1': tensor(0.6135, device='cuda:0'),\n",
      " 'train_loss': tensor(0.6997, device='cuda:0'),\n",
      " 'valid_accuracy': tensor(0.6891, device='cuda:0'),\n",
      " 'valid_f1': tensor(0.6891, device='cuda:0'),\n",
      " 'valid_loss': tensor(0.6467, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Sampler\n",
    "\n",
    "PyTorch Tabular also allows custom batching strategy through Custom Samplers  which comes in handy when working with imbalanced data.\n",
    "\n",
    "Although you can use any sampler, Pytorch Tabular has a few handy utility functions which takes in the target array and implements WeightedRandomSampler using inverse frequency sampling to combat imbalance. This is analogous to preprocessing techniques like Under or OverSampling in traditional ML systems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "from pytorch_tabular.utils import get_balanced_sampler, get_class_weighted_cross_entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "sampler = get_balanced_sampler(train['target'].values.ravel())\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "result = tabular_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeb49718027455aa9690de70955f637",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6460, device='cuda:0'),\n",
      " 'test_f1': tensor(0.6460, device='cuda:0'),\n",
      " 'train_accuracy': tensor(0.5246, device='cuda:0'),\n",
      " 'train_f1': tensor(0.5246, device='cuda:0'),\n",
      " 'train_loss': tensor(0.7055, device='cuda:0'),\n",
      " 'valid_accuracy': tensor(0.6400, device='cuda:0'),\n",
      " 'valid_f1': tensor(0.6400, device='cuda:0'),\n",
      " 'valid_loss': tensor(0.6756, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Weighted Loss\n",
    "\n",
    "If Samplers were like Over/Under Sampling, Custom Weighted Loss is similar to `class_weights`. Depending on the problem, one of these might help you with imbalance. You can easily make calculate the class_weights and provide them to the CrossEntropyLoss using the parameter `weight`. To make this easier, PyTorch Tabular has a handy utility method which calculates smoothed class weights and initializes a weighted loss. Once you have that loss, it's just a matter of passing it to the 1fit1 method using the `loss` parameter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "weighted_loss = get_class_weighted_cross_entropy(train[\"target\"].values.ravel(), mu=0.1)\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, loss=weighted_loss)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "result = tabular_model.evaluate(test)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f44a0fc648d4e4a857d8a2e3cf07f0b",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6684, device='cuda:0'),\n",
      " 'test_f1': tensor(0.6684, device='cuda:0'),\n",
      " 'train_accuracy': tensor(0.6253, device='cuda:0'),\n",
      " 'train_f1': tensor(0.6253, device='cuda:0'),\n",
      " 'train_loss': tensor(0.6659, device='cuda:0'),\n",
      " 'valid_accuracy': tensor(0.6944, device='cuda:0'),\n",
      " 'valid_f1': tensor(0.6944, device='cuda:0'),\n",
      " 'valid_loss': tensor(0.6401, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}